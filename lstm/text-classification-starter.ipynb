{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification starter\n",
    "\n",
    "先读取文件，合并数据和target，分成train和test数据集。用算法训练，这里用到sklearn的naive bayes算法（MultinomialNB）来对train数据集进行分类，再用test数据集测试，得到正确率为92.3%。\n",
    "\n",
    "需要改进的地方：\n",
    "1. 加入semantics语义，尤其是对中文的，并用nltk\n",
    "2. 分析为什么有92.3%\n",
    "3. 研究其他算法的效果\n",
    "4. 调参\n",
    "\n",
    "-- alison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8 \n",
    "#encoding=utf-8\n",
    "\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "from datetime import datetime,date,timedelta\n",
    "import datetime, warnings, scipy\n",
    "from dateutil import parser\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json \n",
    "import csv \n",
    "import sys\n",
    "import os\n",
    "\n",
    "# import nltk\n",
    "# nltk.download()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_data(rootdir, target_name, target_index):\n",
    "    \n",
    "    for root, subdirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            path = root+'/'+file\n",
    "            with open(path, encoding=\"utf8\") as f:\n",
    "                input_file = f.read()\n",
    "                data.append(input_file)\n",
    "                target_names.append(target_name)\n",
    "                target.append(target_index)\n",
    "\n",
    "data = []\n",
    "target_names = []\n",
    "target = []\n",
    "read_data(\"data/classification_data_v3/中性\", \"中性\", 0)\n",
    "read_data(\"data/classification_data_v3/买入\", \"买入\", 1)\n",
    "read_data(\"data/classification_data_v3/卖出\", \"卖出\", 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target_names', 'target']) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine as dataset\n",
    "dataset = {\n",
    "    \"data\" : data,\n",
    "    \"target_names\" :target_names,\n",
    "    \"target\" :target\n",
    "}\n",
    "\n",
    "# print keys\n",
    "print(dataset.keys(),\"\\n\")\n",
    "# print all targets\n",
    "# print(dataset[\"target_names\"])\n",
    "# prints target set\n",
    "set(dataset[\"target\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23769"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = dataset[\"data\"]\n",
    "data_y = dataset[\"target\"]\n",
    "\n",
    "train_x, test_x, train_y, test_y = \\\n",
    "    train_test_split(data_x, data_y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### healper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audit dataframe\n",
    "def table_info(data):\n",
    "    tab_info=pd.DataFrame(data.dtypes).T.rename(index={0:'column type'})\n",
    "    tab_info=tab_info.append(pd.DataFrame(data.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n",
    "    tab_info=tab_info.append(pd.DataFrame(data.isnull().sum()/data.shape[0]*100).T.rename(index={0:'null values (%)'}))\n",
    "    return tab_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table_Page] \n",
      "公告点评|半导体 \n",
      " 证券研究报告 \n",
      " \n",
      " \n",
      "[Table_Title]  [Table_Invest] 买入 \n",
      "华天科技（002185.SZ） 公司评级 \n",
      "当前价格 13.46 元 \n",
      "封测行业景气度提升，有望迎来业绩拐点 合理价值 14.65 元 \n",
      "前次评级 买入 \n",
      "[Table_Summary] 报告日期 2020-03-01 \n",
      "核心观点： \n",
      " \n",
      " 2019 年整体业绩符合预期，短期业绩影响主要由于 2019H1 行业景气 相[Ta对ble市_P场icQ表uot现e]  \n",
      "度下滑以及一次性财务费用造成。公司披露 2019 年业绩快报，2019\n",
      "年实现营业收入 81.05 亿元，同比增长 13.80%；归母净利润 2.98 亿 258%\n",
      "元，同比下滑 23.66%。营收端增长主要是受到收购的 Unisem 并表的 203%\n",
      "影响；而从盈利端来看，受 2019 年上半年行业深度调整，以及公司要 147%\n",
      "约收购 Unisem 所新增的银行贷款导致财务费用同比大幅上升等因素 92%\n",
      "影响，公司 2019 年度归母净利润较上年同期有所下滑。 37%\n",
      " 封测行业整体景气度回升，公司业绩 2019H2 好转明显。2018 年受半 -18%02/19 04/19 06/19 08/19 10/19 12/19\n",
      "导体整体周期下行影响，封测行业增速放缓。2019 年二季度起，随着 华天科技 沪深300  \n",
      "半导体景气度回升，封测行业也明显回暖。华天科技 2019H1 收入为  \n",
      "38.39 亿元，归母净利润为 0.86 亿元；按照业绩快报披露口径测算， [分Ta析ble师_A：uth or]许 兴军 \n",
      "2019H2 收入为 42.65 亿元，同比增长 27.86%，环比 2019H1 增长\n",
      "SAC 执证号：S0260514050002 \n",
      " \n",
      "11.10%。由于 Unisem 在 2019 年 1 月 31 日开始并表，对上下半年影\n",
      "021-60750532 \n",
      "响的差异较小，因此即使考虑  Unisem 并表的因素，2019H2 公司收入\n",
      " xuxingjun@gf.com.cn \n",
      "环比 2019H1 也是增长的。另外，CIS 封测业务处于高景气度下的供\n",
      "分析师： 王亮 \n",
      "应紧张，价格上涨叠加产能扩充将有望为公司带来较大的业绩弹性。 \n",
      "SAC 执证号：S0260519060001 \n",
      " 盈利预测与评级。预计公司 2019~2021 年 EPS 分别为 0.11/0.29/0.38  SFC CE No. BFS478 \n",
      "元/股。同行业可比公司对应 2020 年平均 PE 估值为 73.0X，估值较高\n",
      "021-60750632 \n",
      "主要由于 2020 年尚处于业绩回升过程中。华天科技业绩相对稳定，考  \n",
      " gfwangliang@gf.com.cn \n",
      "虑同行业可比公司估值以及华天科技相对同行业来说较为稳定的业绩\n",
      "分析师： 余高 \n",
      "和历史估值水平，我们给予华天科技 2020 年 50X 的 PE 估值，则合理\n",
      "SAC 执证号：S0260517090001 \n",
      "价值为 14.65 元/股，给予公司“买入”评级。   \n",
      "021-60750632 \n",
      " 风险提示。行业景气度下滑的风险；CIS 行业景气度低于预期的风险；  \n",
      " yugao@gf.com.cn \n",
      "Unisem 整合低于预期的风险。 \n",
      "请注意，许兴军,余高并非香港证券及期货事务监察委员会\n",
      " 的注册持牌人，不可在香港从事受监管活动。 \n",
      "盈利预测：  \n",
      "[Table_Finan [Table_DocReport]  ce] 2017A 2018A 2019E 2020E 2021E 相关研究： \n",
      "营业收入（百万元） 7,010 7,122 8,104 9,836 12,133 华天科技（002185.SZ）:封测 2020-01-10 \n",
      "增长率(%) 28.0 1.6 13.8 21.4 23.4 行业复苏叠加 CIS 高景气度，\n",
      "EBITDA(百万元) 1,148 1,148 1,464 2,161 2,617 \n",
      "有望迎来业绩拐点 \n",
      "归母净利润(百万元) 495 390 298 803 1,038 \n",
      " \n",
      "增长率(%) 26.7 -21.3 -23.6 169.6 29.3 \n",
      "[Table_Contacts] \n",
      "EPS（元/股） 0.23 0.18 0.11 0.29 0.38   \n",
      "市盈率（P/E） 36.67 22.20 68.75 25.50 19.72   \n",
      " \n",
      "市净率（P/B） 3.40 1.52 2.73 2.45 2.19 \n",
      "EV/EBITDA 15.91 8.21 15.95 10.64 8.68 \n",
      "数据来源：公司财务报表，广发证券发展研究中心 \n",
      "   \n",
      "识别风险，发现价值                                      请务必阅读末页的免责声明 \n",
      "1 / 4 \n",
      "[Table_PageText] \n",
      "华天科技|公告点评 \n",
      "  \n",
      " \n",
      "资[Tab产le_F负ina债nce表Det ail] 单位：百万元  现金流量表 单位：百万元 \n",
      "至 12 月 31 日 2017A 2018A 2019E 2020E 2021E  至 12 月 31 日 2017A 2018A 2019E 2020E 2021E \n",
      "流动资产 3,583 5,579 4,519 5,190 6,357 经营活动现金流 904 1,133 1,288 2,165 2,434 \n",
      "货币资金 932 3,097 1,361 1,592 1,957 净利润 547 429 323 854 1,092 \n",
      "应收及预付 1,050 1,156 1,511 1,681 2,073 折旧摊销 583 739 1,026 1,171 1,331 \n",
      "存货 1,428 1,135 1,492 1,745 2,145 营运资金变动 -246 -106 -241 -46 -188 \n",
      "其他流动资产 173 192 155 173 182 其它 20 70 180 186 198 \n",
      "非流动资产 5,783 6,864 10,596 11,096 11,684 投资活动现金流 -1,694 -1,450 -4,752 -1,666 -1,916 \n",
      "长期股权投资 2 36 36 36 36 资本支出 -1,790 -1,632 -4,841 -1,666 -1,916 \n",
      "固定资产 4,508 5,679 8,175 8,827 9,519 投资变动 -2 -35 87 0 0 \n",
      "在建工程 497 401 701 551 451 其他 99 217 2 0 0 \n",
      "无形资产 163 177 416 413 410 筹资活动现金流 562 2,688 1,729 -268 -152 \n",
      "其他长期资产 613 570 1,268 1,268 1,268 银行借款 612 2,815 383 -127 85 \n",
      "资产总计 9,366 12,443 15,116 16,286 18,042 股权融资 0 0 1,647 0 0 \n",
      "流动负债 2,706 4,420 5,223 5,503 6,226 其他 -53 -127 -301 -141 -237 \n",
      "短期借款 532 2,101 2,454 2,328 2,412 现金净增加额 -228 2,371 -1,736 231 365 \n",
      "应付及预收 1,706 1,588 1,905 2,230 2,742 期初现金余额 927 694 3,097 1,361 1,592 \n",
      "其他流动负债 467 732 863 945 1,072 期末现金余额 694 3,058 1,361 1,592 1,957 \n",
      "非流动负债 665 1,648 1,678 1,678 1,678       \n",
      "长期借款 409 1,374 1,404 1,404 1,404       \n",
      "应付债券 0 0 0 0 0       \n",
      "其他非流动负债 256 274 274 274 274        \n",
      "负债合计 3,371 6,068 6,900 7,180 7,904        \n",
      "股本 2,131 2,131 2,740 2,740 2,740          \n",
      "资本公积 1,128 1,131 2,168 2,168 2,168 主要财务比率      \n",
      "留存收益 2,081 2,429 2,684 3,436 4,414 至 12 月 31 日 2017A 2018A 2019E 2020E 2021E \n",
      "归 属母公司股东权益 5,347 5,695 7,510 8,349 9,327 成长能力      \n",
      "少数股东权益 649 680 706 757 811  营业收入增长 28.0% 1.6% 13.8% 21.4% 23.4% \n",
      "负债和股东权益 9,366 12,443 15,116 16,286 18,042  营业利润增长 52.1% -22.3% -12.8% 134.6% 28.0% \n",
      "       归母净利润增长 26.7% -21.3% -23.6% 169.6% 29.3% \n",
      "       获利能力      \n",
      "利润表    单位： 百万元  毛利率 17.9% 16.3% 16.0% 19.1% 19.3% \n",
      "至 12 月 31 日 2017A 2018A 2019E 2020E 2021E  净利率 7.8% 6.0% 4.0% 8.7% 9.0% \n",
      "营业收入 7,010 7,122 8,104 9,836 12,133 ROE 9.3% 6.8% 4.0% 9.6% 11.1% \n",
      "营业成本 5,755 5,959 6,807 7,960 9,786 ROIC 8.1% 5.2% 3.0% 7.2% 8.8% \n",
      "营业税金及附加 31 28 32 39 49 偿债能力      \n",
      "销售费用 74 80 97 118 140 资产负债率 36.0% 48.8% 45.7% 44.1% 43.8% \n",
      "管理费用 231 262 357 334 388 净负债比率 11.1% 31.1% 28.1% 25.3% 23.3% \n",
      "研发费用 353 384 373 393 485 流动比率 1.32 1.26 0.87 0.94 1.02 \n",
      "财务费用 6 14 130 78 79 速动比率 0.78 1.00 0.57 0.61 0.66 \n",
      "资产减值损失 25 15 14 12 25 营运能力      \n",
      "公允价值变动收益 0 0 0 0 0 总资产周转率 0.82 0.65 0.59 0.63 0.71 \n",
      "投资净收益 4 0 2 0 0 应收账款周转率 7.40 6.66 5.62 6.08 6.08 \n",
      "营业利润 629 489 427 1,001 1,281 存货周转率 5.04 4.65 4.56 4.56 4.56 \n",
      "营业外收支 2 -9 4 4 4 每股指标（元）      \n",
      "利润总额 631 480 431 1,005 1,285 每股收益 0.23 0.18 0.11 0.29 0.38 \n",
      "所得税 84 51 108 151 193 每股经营现金流 0.42 0.53 0.47 0.79 0.89 \n",
      "净利润 547 429 323 854 1,092 每股净资产 2.51 2.67 2.74 3.05 3.40 \n",
      "少数股东损益 52 39 25 51 55 估值比率      \n",
      "归属母公司净利润 495 390 298 803 1,038 P/E 36.67 22.20 68.75 25.50 19.72 \n",
      "EBITDA 1,148 1,148 1,464 2,161 2,617 P/B 3.40 1.52 2.73 2.45 2.19 \n",
      "EPS（元） 0.23 0.18 0.11 0.29 0.38 EV/EBITDA 15.91 8.21 15.95 10.64 8.68 \n",
      "识别风险，发现价值                            请务必阅读末页的免责声明 \n",
      "2 / 4 \n",
      "[Table_PageText] \n",
      "华天科技|公告点评 \n",
      "  \n",
      " \n",
      " \n",
      "广[Tab发le_R证esea券rch电Team子] 元器件和半导体研究小组 \n",
      "许 兴 军 ： 首席分析师，浙江大学系统科学与工程学士，浙江大学系统分析与集成硕士，2012 年加入广发证券发展研究中心，带领团队荣\n",
      "获 2019 年新财富电子行业第一名。 \n",
      "王   亮 ： 资深分析师，复旦大学经济学硕士，2014 年加入广发证券发展研究中心 \n",
      "王   璐 ： 资深分析师，复旦大学微电子与固体电子学硕士，2015 年加入广发证券发展研究中心。 \n",
      "余   高 ： 资深分析师，复旦大学物理学学士，复旦大学国际贸易学硕士，2015 年加入广发证券发展研究中心。 \n",
      "彭   雾 ： 资深分析师，复旦大学微电子与固体电子学硕士，2016 年加入广发证券发展研究中心。 \n",
      "王 昭 光 ： 研究助理，浙江大学材料科学与工程学士，上海交通大学材料科学与工程硕士，2018 年加入广发证券发展研究中心。 \n",
      "蔡 锐 帆 ： 研究助理，北京大学汇丰商学院硕士，2019 年加入广发证券发展研究中心。 \n",
      " \n",
      "广[Tab发le_In证dus券tryIn—vest行Des业cript投ion] 资评级说明 \n",
      "买入： 预期未来 12 个月内，股价表现强于大盘 10%以上。 \n",
      "持有： 预期未来 12 个月内，股价相对大盘的变动幅度介于-10%～+10%。 \n",
      "卖出： 预期未来 12 个月内，股价表现弱于大盘 10%以上。 \n",
      " \n",
      "[广Tab发le_C证omp券any—Inve公stDe司scri投ption资] 评级说明 \n",
      "买入： 预期未来 12 个月内，股价表现强于大盘 15%以上。 \n",
      "增持： 预期未来 12 个月内，股价表现强于大盘 5%-15%。 \n",
      "持有： 预期未来 12 个月内，股价相对大盘的变动幅度介于-5%～+5%。 \n",
      "卖出： 预期未来 12 个月内，股价表现弱于大盘 5%以上。 \n",
      " \n",
      "[联Tab系le_A我ddre们ss]  \n",
      " 广州市 深圳市 北京市 上海市 香港 \n",
      "地址 广州市天河区马场路 深圳市福田区益田路 北京市西城区月坛北街 上海市浦东新区世纪大 香港中环干诺道中 111\n",
      "26 号广发证券大厦 35 6001 号太平金融大厦 2 号月坛大厦 18 层 道8号国金中心一期16 号永安中心 14 楼\n",
      "楼 31 层 楼 1401-1410 室 \n",
      "邮政编码 510627 518026 100045 200120   \n",
      "客服邮箱 gfyf@gf.com.cn \n",
      " \n",
      "法[Tab律le_L主egal体Disc声laim明er]  \n",
      "本报告由广发证券股份有限公司或其关联机构制作，广发证券股份有限公司及其关联机构以下统称为“广发证券”。本报告的分销依据不同国家、\n",
      "地区的法律、法规和监管要求由广发证券于该国家或地区的具有相关合法合规经营资质的子公司/经营机构完成。 \n",
      "广发证券股份有限公司具备中国证监会批复的证券投资咨询业务资格，接受中国证监会监管，负责本报告于中国（港澳台地区除外）的分销。 \n",
      "广发证券（香港）经纪有限公司具备香港证监会批复的就证券提供意见（4 号牌照）的牌照，接受香港证监会监管，负责本报告于中国香港地\n",
      "区的分销。 \n",
      "本报告署名研究人员所持中国证券业协会注册分析师资质信息和香港证监会批复的牌照信息已于署名研究人员姓名处披露。  \n",
      " \n",
      "[重Tab要le_Im声por明tant Notices] \n",
      "识别风险，发现价值                            请务必阅读末页的免责声明 \n",
      "3 / 4 \n",
      "[Table_PageText] \n",
      "华天科技|公告点评 \n",
      "  \n",
      " \n",
      "广发证券股份有限公司及其关联机构可能与本报告中提及的公司寻求或正在建立业务关系，因此，投资者应当考虑广发证券股份有限公司及其\n",
      "关联机构因可能存在的潜在利益冲突而对本报告的独立性产生影响。投资者不应仅依据本报告内容作出任何投资决策。 \n",
      "本报告署名研究人员、联系人（以下均简称“研究人员”）针对本报告中相关公司或证券的研究分析内容，在此声明：（1）本报告的全部分析结\n",
      "论、研究观点均精确反映研究人员于本报告发出当日的关于相关公司或证券的所有个人观点，并不代表广发证券的立场；（2）研究人员的部分\n",
      "或全部的报酬无论在过去、现在还是将来均不会与本报告所述特定分析结论、研究观点具有直接或间接的联系。 \n",
      "研究人员制作本报告的报酬标准依据研究质量、客户评价、工作量等多种因素确定，其影响因素亦包括广发证券的整体经营收入，该等经营收\n",
      "入部分来源于广发证券的投资银行类业务。 \n",
      "本报告仅面向经广发证券授权使用的客户/特定合作机构发送，不对外公开发布，只有接收人才可以使用，且对于接收人而言具有保密义务。广\n",
      "发证券并不因相关人员通过其他途径收到或阅读本报告而视其为广发证券的客户。在特定国家或地区传播或者发布本报告可能违反当地法律，\n",
      "广发证券并未采取任何行动以允许于该等国家或地区传播或者分销本报告。 \n",
      "本报告所提及证券可能不被允许在某些国家或地区内出售。请注意，投资涉及风险，证券价格可能会波动，因此投资回报可能会有所变化，过\n",
      "去的业绩并不保证未来的表现。本报告的内容、观点或建议并未考虑任何个别客户的具体投资目标、财务状况和特殊需求，不应被视为对特定\n",
      "客户关于特定证券或金融工具的投资建议。本报告发送给某客户是基于该客户被认为有能力独立评估投资风险、独立行使投资决策并独立承担\n",
      "相应风险。 \n",
      "本报告所载资料的来源及观点的出处皆被广发证券认为可靠，但广发证券不对其准确性、完整性做出任何保证。报告内容仅供参考，报告中的\n",
      "信息或所表达观点不构成所涉证券买卖的出价或询价。广发证券不对因使用本报告的内容而引致的损失承担任何责任，除非法律法规有明确规\n",
      "定。客户不应以本报告取代其独立判断或仅根据本报告做出决策，如有需要，应先咨询专业意见。 \n",
      "广发证券可发出其它与本报告所载信息不一致及有不同结论的报告。本报告反映研究人员的不同观点、见解及分析方法，并不代表广发证券的\n",
      "立场。广发证券的销售人员、交易员或其他专业人士可能以书面或口头形式，向其客户或自营交易部门提供与本报告观点相反的市场评论或交\n",
      "易策略，广发证券的自营交易部门亦可能会有与本报告观点不一致，甚至相反的投资策略。报告所载资料、意见及推测仅反映研究人员于发出\n",
      "本报告当日的判断，可随时更改且无需另行通告。广发证券或其证券研究报告业务的相关董事、高级职员、分析师和员工可能拥有本报告所提\n",
      "及证券的权益。在阅读本报告时，收件人应了解相关的权益披露（若有）。 \n",
      "本研究报告可能包括和/或描述/呈列期货合约价格的事实历史信息（“信息”）。请注意此信息仅供用作组成我们的研究方法/分析中的部分论点/\n",
      "依据/证据，以支持我们对所述相关行业/公司的观点的结论。在任何情况下，它并不（明示或暗示）与香港证监会第 5 类受规管活动（就期货\n",
      "合约提供意见）有关联或构成此活动。 \n",
      " \n",
      "权[Table益_Inte披restD露isclos ure] \n",
      "(1)广发证券（香港）跟本研究报告所述公司在过去 12 个月内并没有任何投资银行业务的关系。 \n",
      " \n",
      "版[Tab权le_C声opyr明ight ] \n",
      "未经广发证券事先书面许可，任何机构或个人不得以任何形式翻版、复制、刊登、转载和引用，否则由此造成的一切不良后果及法律责任由私\n",
      "自翻版、复制、刊登、转载和引用者承担。 \n",
      " \n",
      "识别风险，发现价值                            请务必阅读末页的免责声明 \n",
      "4 / 4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#prints the first data file\n",
    "print(\"\\n\".join(train_x[0].split(\"\\n\")[:])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing - pipelined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algo1 - Naive base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "text_clf_nb = Pipeline([('vect', CountVectorizer()), # attribute stop_words (\"then, the, etc.\")\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB(alpha=0.01)), # FitPrior=False, a uniform prior will be used\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_nb = text_clf_nb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8169962137147665"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf_nb.predict(test_x)\n",
    "np.mean(predicted == test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_single = text_clf_nb.predict(test_x[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_single)\n",
    "print(test_y[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8169962137147665"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_nb.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algo2 - Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf-svm', SGDClassifier(loss='hinge', \n",
    "                                               penalty='l2',\n",
    "                                               alpha=1e-3, \n",
    "                                               random_state=42)),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_svm = text_clf_svm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7541018090029449"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_svm = text_clf_svm.predict(test_x)\n",
    "np.mean(predicted_svm == test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7541018090029449"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_svm.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_nb = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\idgca\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 404, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n  File \"C:\\Users\\idgca\\Anaconda3\\lib\\multiprocessing\\queues.py\", line 111, in get\n    res = self._recv_bytes()\n  File \"C:\\Users\\idgca\\Anaconda3\\lib\\multiprocessing\\connection.py\", line 216, in recv_bytes\n    buf = self._recv_bytes(maxlength)\n  File \"C:\\Users\\idgca\\Anaconda3\\lib\\multiprocessing\\connection.py\", line 318, in _recv_bytes\n    return self._get_more_data(ov, maxsize)\n  File \"C:\\Users\\idgca\\Anaconda3\\lib\\multiprocessing\\connection.py\", line 340, in _get_more_data\n    ov, err = _winapi.ReadFile(self._handle, left, overlapped=True)\nMemoryError\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-320139bf0c35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgs_clf_nb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_clf_nb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters_nb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgs_clf_nb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs_clf_nb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
     ]
    }
   ],
   "source": [
    "gs_clf_nb = GridSearchCV(text_clf_nb, parameters_nb, n_jobs=-1)\n",
    "gs_clf_nb = gs_clf_nb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf_nb.best_params_\n",
    "gs_clf_nb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf-svm__alpha': (1e-2, 1e-3),\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf_svm.best_params_\n",
    "gs_clf_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    public int longestSubarray(int[] nums, int limit) {\n",
    "        TreeMap map = new TreeMap<>();\n",
    "        int left = 0;\n",
    "        int right = 0;\n",
    "        int res = 0;\n",
    "        while(right < nums.length) {\n",
    "            map.put(nums[right], map.getOrDefault(nums[right],0)+1);\n",
    "            \n",
    "            while(map.lastKey() - map.firstKey() > limit) {\n",
    "                map.replace(nums[left], map.get(nums[left])-1);\n",
    "                if(map.get(nums[left]) == 0) {\n",
    "                    map.remove(nums[left]);\n",
    "                }\n",
    "                left++;\n",
    "            }\n",
    "            res = Math.max(res, right - left + 1);\n",
    "            right++;\n",
    "        }\n",
    "        return res;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
